{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recreate the ixnos model in this notebook\n",
    "Make a pytorch model w the same architecture and try to load in the pickled weights and biases\n",
    "into that model. Then, find sensible outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {device} device\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iXnos(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=760, out_features=200, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=200, out_features=1, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n",
      "layers.0.weight torch.Size([200, 760])\n",
      "layers.0.bias torch.Size([200])\n",
      "layers.2.weight torch.Size([1, 200])\n",
      "layers.2.bias torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "class iXnos(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(760, 200),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(200, 1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x = self.flatten(x)\n",
    "        output = self.layers(x)\n",
    "        return output \n",
    "    \n",
    "\n",
    "model = iXnos().to(device)\n",
    "print(model)\n",
    "for key, value in model.state_dict().items():\n",
    "    print(key, value.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([200, 760])\n",
      "torch.Size([200])\n",
      "torch.Size([1, 200])\n",
      "torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "pklpath = \"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/lasagne_nn/full_cod_n5p4_nt_n15p14_rep0/epoch70/codon_scores.pkl\"\n",
    "pklpath = \"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/lasagne_nn/full_cod_n5p4_nt_n15p14_rep0/epoch70/weights.pkl\"\n",
    "# Open the file in read-binary mode\n",
    "with open(pklpath, 'rb') as file:\n",
    "    # Load the pickled data\n",
    "    data = pickle.load(file, encoding='bytes')\n",
    "\n",
    "# data#.shape\n",
    "len(data)\n",
    "for idx, val in enumerate(data):\n",
    "    data[idx] = torch.from_numpy(val).T\n",
    "    print(data[idx].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iXnos(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=760, out_features=200, bias=True)\n",
      "    (1): Tanh()\n",
      "    (2): Linear(in_features=200, out_features=1, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "dummy = \"layers\"\n",
    "labels = [f\"{dummy}.0.weight\", f\"{dummy}.0.bias\", f\"{dummy}.2.weight\", f\"{dummy}.2.bias\"]\n",
    "\n",
    "old_model = OrderedDict(zip(labels, data))\n",
    "\n",
    "model.load_state_dict(old_model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([14.8665], grad_fn=<ReluBackward0>)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand(760))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try to get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['GCA', 'GCA', 'GCA']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: add a larger sequence class that checks that everything is valid and\n",
    "# makes decisions about truncating ends of the overall sequence before formatting\n",
    "# it to be fed into the model. Tbh this is a placeholder class for now\n",
    "class Footprint():\n",
    "    def __init__(self, sequence):\n",
    "        self.sequence = sequence\n",
    "        self.codons = self.get_codons()\n",
    "\n",
    "    def get_codons(self):\n",
    "        return [self.sequence[i:i+3] for i in range(0, len(self.sequence), 3)]\n",
    "    \n",
    "\n",
    "f = Footprint(\"GCAGCAGCA\")\n",
    "f.codons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, True]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[f.codons[i] == \"GCA\" for i in range(len(f.codons))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=\"ACGT\"\n",
    "nts = [\"A\", \"C\", \"G\", \"T\"]\n",
    "codons = [x+y+z for x in alpha for y in alpha for z in alpha]\n",
    "cod2id = {codon:idx for idx, codon in enumerate(codons)}\n",
    "id2cod = {idx:codon for codon, idx in cod2id.items()}\n",
    "nt2id = {nt:idx for idx, nt in enumerate(alpha)}\n",
    "id2nt = {idx:nt for nt, idx in nt2id.items()}\n",
    "\n",
    "# len(nts)\n",
    "# len(codons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`/mnt/lareaulab/shelen/clean_vestigium` has helen's stuff\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['expt_dir', 'out_dir', 'loss_fn', 'drop_zeros', 'y_tr', 'gene_len_fname', 'tr_codons_fname', 'y_te', 'outputs_fname', 'rel_struc_idxs', 'gene_seq_fname', 'rel_nt_idxs', 'rel_cod_idxs', 'log_y', 'lr_decay', 'momentum', 'filter_max', 'struc_fname', 'input_drop_rate', 'raw_psct', 'learning_rate', 'batch_size', 'update_method', 'max_struc_width', 'aa_feats', 'filter_test', 'filter_pct', 'hidden_drop_rate', 'name', 'nonlinearity', 'widths', 'scaled_psct', 'nonnegative', 'max_struc_start_idx', 'num_outputs', 'te_codons_fname'])\n",
      "[-15, -14, -13, -12, -11, -10, -9, -8, -7, -6, -5, -4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n",
      "[-5, -4, -3, -2, -1, 0, 1, 2, 3, 4]\n"
     ]
    }
   ],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_csv(\"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/process/outputs.size.27.30.txt\", sep=\"\\t\")\n",
    "\n",
    "with open(\"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/lasagne_nn/full_cod_n5p4_nt_n15p14_rep0/init_data/y_te.pkl\", \"rb\") as file:\n",
    "    y_te = pickle.load(file, encoding='bytes')\n",
    "with open(\"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/lasagne_nn/full_cod_n5p4_nt_n15p14_rep0/init_data/init_data.pkl\", \"rb\") as file:\n",
    "    X = pickle.load(file, encoding='bytes')\n",
    "\n",
    "X = {key.decode('utf-8'): value for key, value in X.items()}\n",
    "\n",
    "y_te\n",
    "print(X.keys())\n",
    "# print(X['rel_struc_idxs'])\n",
    "print(X['rel_nt_idxs'])\n",
    "print(X['rel_cod_idxs'])\n",
    "# for key, value in X.items():\n",
    "#     print(key, \": \", value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# NOTE: This file appears to contain the training data, so codons -> scaled counts\n",
    "fname = \"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/process/tr_set_bounds.size.27.30.trunc.20.20.min_cts.200.min_cod.100.top.500.data_table.txt\"\n",
    "\n",
    "# fname = \"/mnt/lareaulab/demaray/lareau-rotation/iXnos/expts/iwasaki/process/te_set_bounds.size.27.30.trunc.20.20.min_cts.200.min_cod.100.top.500.data_table.txt\"\n",
    "# NOTE: looks like they start with the 20th codon, and likely that they end 20 codons early here\n",
    "df = pd.read_csv(fname, sep='\\t')\n",
    "# NOTE: I won't be able to use this for the first ~5 codons bc I don't know what the preceding codons / nts are, but it's OK for now. \n",
    "genes_truncated = df.groupby(\"gene\")[\"cod_seq\"].agg(''.join) # We'll need this for nt features. \n",
    "\n",
    "nt_idx = np.arange(-15, 15)\n",
    "cod_idx = np.arange(-5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gene          ENST00000022615.7\n",
      "cod_idx                     151\n",
      "cod_seq                     GGC\n",
      "raw_cts                     4.0\n",
      "scaled_cts             0.695414\n",
      "Name: 131, dtype: object\n"
     ]
    }
   ],
   "source": [
    "te = df.iloc[131]\n",
    "gene = te[\"gene\"]\n",
    "# TODO: get codon indices\n",
    "\n",
    "print(te)\n",
    "def codon_1he(codon, codons=codons): # Should be a class thing so I don't need to sus input codons\n",
    "    arr = np.zeros(64)\n",
    "    arr[codons.index(codon)] = 1\n",
    "    return arr\n",
    "\n",
    "n5p4 = cod_idx + te[\"cod_idx\"]\n",
    "codon_vector = []\n",
    "for cod in n5p4: \n",
    "    codon_vector.append(codon_1he(df.loc[(df['gene'] == gene) & (df['cod_idx'] == cod), \"cod_seq\"].item()))\n",
    "codon_vector = np.concatenate(codon_vector)\n",
    "# TODO: get nt indices (which nt in the A site is 0??)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GGC\n"
     ]
    }
   ],
   "source": [
    "def nt_1he(nt, nts=nts): # Should be a class thing so I don't need to sus input nts\n",
    "    arr = np.zeros(4)\n",
    "    arr[nts.index(nt)] = 1\n",
    "    return arr\n",
    "\n",
    "\n",
    "\n",
    "gene = genes_truncated[te['gene']]\n",
    "asite_nt_idx = 2 + (te['cod_idx'] - 20) * 3\n",
    "print(gene[asite_nt_idx - 2: asite_nt_idx + 1])\n",
    "assert gene[asite_nt_idx] == te['cod_seq'][-1]\n",
    "\n",
    "nt_vector = []\n",
    "for i in nt_idx + asite_nt_idx:\n",
    "    nt_vector.append(nt_1he(gene[i]))\n",
    "nt_vector = np.concatenate(nt_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = np.concatenate([codon_vector, nt_vector])\n",
    "input = torch.from_numpy(input).to(torch.float32)\n",
    "model(input).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def pred(i):\n",
    "    te = df.iloc[i]\n",
    "    gene = te[\"gene\"]\n",
    "    # TODO: get codon indices\n",
    "\n",
    "    # print(te)\n",
    "    def codon_1he(codon, codons=codons): # Should be a class thing so I don't need to sus input codons\n",
    "        arr = np.zeros(64)\n",
    "        arr[codons.index(codon)] = 1\n",
    "        return arr\n",
    "\n",
    "    n5p4 = cod_idx + te[\"cod_idx\"]\n",
    "    codon_vector = []\n",
    "    for cod in n5p4: \n",
    "        codon_vector.append(codon_1he(df.loc[(df['gene'] == gene) & (df['cod_idx'] == cod), \"cod_seq\"].item()))\n",
    "    codon_vector = np.concatenate(codon_vector)\n",
    "\n",
    "    def nt_1he(nt, nts=nts): # Should be a class thing so I don't need to sus input nts\n",
    "        arr = np.zeros(4)\n",
    "        arr[nts.index(nt)] = 1\n",
    "        return arr\n",
    "\n",
    "\n",
    "\n",
    "    gene = genes_truncated[te['gene']]\n",
    "    asite_nt_idx = 2 + (te['cod_idx'] - 20) * 3\n",
    "    # print(gene[asite_nt_idx - 2: asite_nt_idx + 1])\n",
    "    assert gene[asite_nt_idx] == te['cod_seq'][-1]\n",
    "\n",
    "    nt_vector = []\n",
    "    for i in nt_idx + asite_nt_idx:\n",
    "        nt_vector.append(nt_1he(gene[i]))\n",
    "    nt_vector = np.concatenate(nt_vector)\n",
    "\n",
    "    input = np.concatenate([codon_vector, nt_vector])\n",
    "    input = torch.from_numpy(input).to(torch.float32)\n",
    "    return te['scaled_cts'].item(), model(input).item()\n",
    "\n",
    "\n",
    "real, predicted = [], []\n",
    "for i in range(6, 100):\n",
    "    r, p = pred(i)\n",
    "    real.append(r)\n",
    "    predicted.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f0ae4712d80>"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(real, predicted, s=5, c='k')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
